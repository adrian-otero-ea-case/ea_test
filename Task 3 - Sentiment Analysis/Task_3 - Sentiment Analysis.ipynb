{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tweepy\n",
    "import csv\n",
    "import json \n",
    "import datetime\n",
    "\n",
    "from pandas.io import sql\n",
    "from sqlalchemy import create_engine\n",
    "from mysql import connector\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "\n",
    "from google.cloud import language\n",
    "from google.cloud.language import enums\n",
    "from google.cloud.language import types\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Twitter API Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "consumer_key = 'JHi9h2byuCWorokMLCIbh20KI'\n",
    "consumer_secret = 'k0ysvIDGu4YGswrqab76NFmroVmOxN9r2JuapfaoYYoXb3BrXO'\n",
    "access_token = '1186208049058500608-V3EVjBiZbwx9Aqmn3asu65Gb1j05zx'\n",
    "access_token_secret = 'QgesjDM7QGVCHCkDQqhXs2WUYk6jmTM9iy01Cc6n4VtOC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Natural Language API Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp_client = language.LanguageServiceClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure connection with Cloud SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user='ea-developer'\n",
    "host='35.205.32.16'\n",
    "port='3306'\n",
    "db='ea_datalake'\n",
    "database_connection = create_engine('mysql+mysqlconnector://{0}:@{1}:{2}/{3}'.format(user, host, port, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure connection with Bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigquery_client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure connection with Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Instantiates a client\n",
    "storage_client = storage.Client()\n",
    "\n",
    "# The name for the new bucket\n",
    "bucket_name = 'ea-datalake-dev'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "\n",
    "    print('File {} uploaded to {}.'.format(\n",
    "        source_file_name,\n",
    "        destination_blob_name))\n",
    "    \n",
    "def list_blobs(bucket_name):\n",
    "    \"\"\"Lists all the blobs in the bucket.\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "    blobs = bucket.list_blobs()\n",
    "\n",
    "    for blob in blobs:\n",
    "        print(blob.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Extract data from Twitter using API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hashtag = '#FIFA20'\n",
    "\n",
    "columns=['tweet_id', 'tweet_createat', 'tweet_text', 'tweet_lang', \n",
    "         'tweet_country', 'tweet_country_code',\n",
    "         'tweet_retweets', 'tweet_favourites',\n",
    "         'user_id', 'user_name', 'user_location', 'user_followers',\n",
    "         'sentiment_score', 'sentiment_magnitude']\n",
    "\n",
    "support_langs = ['zh','zh-Hant','en','fr','de','it','ja','ko','pt','es']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Search API to find located tweets with the hashtag #FIFA20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "msgs = []\n",
    "msg =[]\n",
    "\n",
    "for tweet in tweepy.Cursor(api.search, q=hashtag, rpp=100).items():\n",
    "    \n",
    "        # Extract location details\n",
    "        country = ''\n",
    "        country_code = ''    \n",
    "        if tweet.place is not None:\n",
    "            country = tweet.place.country\n",
    "            country_code = tweet.place.country_code\n",
    "            \n",
    "        if tweet.lang is not None:\n",
    "            if tweet.lang in support_langs:\n",
    "                \n",
    "                NOK = NOK - 1\n",
    "                OK = OK + 1\n",
    "                print('OK: ', OK, ' // NOK: ', NOK)\n",
    "\n",
    "                # Use Google NLP API to Analyze the sentiment of the text\n",
    "                document = types.Document(\n",
    "                    content=tweet.text,\n",
    "                    language=tweet.lang,\n",
    "                    type=enums.Document.Type.PLAIN_TEXT)\n",
    "                sentiment = client.analyze_sentiment(document=document).document_sentiment\n",
    "\n",
    "                # Create a tuple with all the fields (Twitter + Sentiment)\n",
    "                msg = [tweet.id_str, tweet.created_at, tweet.text, tweet.lang, \n",
    "                       country, country_code, \n",
    "                       tweet.retweet_count, tweet.favorite_count, \n",
    "                       tweet.user.id_str, tweet.user.screen_name, tweet.user.location, tweet.user.followers_count,\n",
    "                       sentiment.score, sentiment.magnitude]\n",
    "\n",
    "            msg = tuple(msg)\n",
    "            msgs.append(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add column names\n",
    "df_tweets = pd.DataFrame(msgs)\n",
    "df_tweets.columns = columns\n",
    "df_tweets = df_tweets[df_tweets.tweet_country.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_tweets['tweet_sentiment'] = np.where(df_tweets['sentiment_score'] > 0.3, \n",
    "                                        '5. Very Positive',\n",
    "                               np.where((df_tweets['sentiment_score'] >= 0.1) & (df_tweets['sentiment_score'] < 0.3),\n",
    "                                        '4. Positive',\n",
    "                               np.where((df_tweets['sentiment_score'] > (-0.3)) & (df_tweets['sentiment_score'] <= (-0.1)), \n",
    "                                        '2. Negative',\n",
    "                               np.where(df_tweets['sentiment_score'] <= (-0.3), \n",
    "                                        '1. Very Negative', '3. Neutral'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adrian_otero_ea_case/anaconda3/lib/python3.5/site-packages/google/cloud/bigquery/_pandas_helpers.py:275: UserWarning: Unable to determine type of column 'tweet_id'.\n",
      "  warnings.warn(u\"Unable to determine type of column '{}'.\".format(column))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.job.LoadJob at 0x7f6e5285b080>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_ref = bigquery_client.dataset('ea')\n",
    "table_ref = dataset_ref.table('ea_fifa_20_tweets')\n",
    "\n",
    "bigquery_client.load_table_from_dataframe(df_tweets, table_ref).result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
